# üì§ Upload Processing Module

> **Admin Excel Upload and RAG Processing**

This folder contains the main admin workflow script for uploading Excel files and running the full RAG pipeline.

---

## üìÅ Structure

```
upload/
‚îú‚îÄ‚îÄ README.md
‚îî‚îÄ‚îÄ admin_upload_and_merge_with_rag.py     # Main workflow script
```

---

## üì¶ Main Function: `upload_and_merge_with_rag()`

Orchestrates the complete 6-step admin workflow from Excel upload to ChromaDB update.

```python
from admin.upload.admin_upload_and_merge_with_rag import upload_and_merge_with_rag

# Run full workflow
result = upload_and_merge_with_rag(
    excel_file_path="path/to/uploaded_file.xlsx"
)

# Returns summary dictionary
print(result['total_processed'])
print(result['new_records'])
print(result['updated_records'])
```

---

## üîÑ 6-Step Workflow

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    upload_and_merge_with_rag()               ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 1: Semantic Analysis                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Read Excel file                                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Clean data (remove blanks, footers)                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Standardize column names                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Run ComprehensiveSRAnalyzer                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 2: Save Initial Results                                ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Save to output/reports/Admin_Upload_TIMESTAMP.xlsx      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 3: Prepare for RAG                                     ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Merge semantic workarounds with original data           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Save to RAG/input/ for pipeline                         ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 4: Run RAG Pipeline                                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Initialize MultiModelSRPipeline                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Process all SRs with 5 LLM calls                        ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Save output to RAG/llm output/                          ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Log usage statistics                                    ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 5: Merge to ChromaDB                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ For each SR:                                            ‚îÇ
‚îÇ  ‚îÇ   ‚îú‚îÄ‚îÄ If exists: UPDATE (preserve user feedback)          ‚îÇ
‚îÇ  ‚îÇ   ‚îî‚îÄ‚îÄ If new: INSERT                                      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Track new vs updated counts                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 5.5: Inject New SRs                                    ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Only inject truly new SRs to vector store               ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 5.6: Cleanup                                           ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Delete temp files from RAG input/output                 ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  STEP 6: Generate Summary                                    ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Total processed                                         ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ New vs updated counts                                   ‚îÇ
‚îÇ  ‚îú‚îÄ‚îÄ Assignment distribution                                 ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ Error count                                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Helper Functions

### `clean_excel_data(df)`
Removes blank rows and date footers from Excel.

```python
def clean_excel_data(df: pd.DataFrame) -> pd.DataFrame:
    """
    Cleaning steps:
    1. Remove rows where all columns are NaN
    2. Remove footer rows (date patterns like "12/5/2024")
    3. Reset index
    """
```

### `standardize_columns(df)`
Maps various column name formats to standard names.

```python
# Column mapping examples:
{
    'call id': 'Call ID',
    'sr id': 'SR ID',
    'case id': 'Call ID',
    'description': 'Description',
    'notes': 'Notes',
    'wl summary': 'Notes',
    'priority': 'Priority'
}
```

---

## üìä Output Summary

The function returns a summary dictionary:

```python
{
    'total_processed': 50,
    'new_records': 35,
    'updated_records': 15,
    'errors': 0,
    'assignment_distribution': {
        'John Smith': 12,
        'Jane Doe': 10,
        'Bob Wilson': 8,
        ...
    },
    'rag_output_path': 'RAG/llm output/...',
    'semantic_output_path': 'output/reports/...'
}
```

---

## üîß Configuration

### File Size Limit
```python
MAX_FILE_SIZE = 16 * 1024 * 1024  # 16MB
```

### Supported Formats
```python
ALLOWED_EXTENSIONS = ['.xls', '.xlsx']
```

---

## üîó Integration Points

### Called By
- `app/routes/admin.py` - Web upload endpoint
- `main_runner.py` - CLI runner
- Scheduled jobs

### Calls
- `ComprehensiveSRAnalyzer` - Semantic analysis
- `MultiModelSRPipeline` - RAG processing
- `HistoryDatabaseManager` - ChromaDB updates

---

## ‚ö†Ô∏è Error Handling

The script includes robust error handling:

```python
try:
    # Step 4: Run RAG Pipeline
    pipeline = MultiModelSRPipeline()
    pipeline.run()
except Exception as e:
    logger.error(f"RAG pipeline failed: {e}")
    # Fallback: Use semantic-only results
    rag_output = semantic_output
```

---

## üìà Logging

Detailed logging for each step:

```
INFO: Step 1: Starting semantic analysis...
INFO: Cleaned 50 rows from Excel
INFO: Step 2: Saving initial results...
INFO: Step 3: Preparing for RAG pipeline...
INFO: Step 4: Running RAG pipeline...
INFO: LLM Usage - Total calls: 125, Cost: $0.45
INFO: Step 5: Merging to ChromaDB...
INFO: New: 35, Updated: 15
INFO: Step 6: Complete - 50 SRs processed
```

---

*Part of SR-Analyzer Admin Module*
