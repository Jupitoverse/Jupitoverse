# ğŸš€ SR-Analyzer: Intelligent Service Request Analysis System

> **AI-Powered Multi-Model RAG Pipeline for Automated SR Resolution**

An enterprise-grade Service Request (SR) analysis system that leverages 5 specialized LLM calls, semantic search across 1.18M+ historical records, and intelligent team assignment to automate SR triage and resolution.

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Key Features](#key-features)
- [Architecture](#architecture)
- [5-LLM Pipeline](#5-llm-pipeline)
- [Quick Start](#quick-start)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Usage](#usage)
- [API Reference](#api-reference)

---

## ğŸ¯ Overview

The SR-Analyzer system transforms how Service Requests are processed by:

1. **Semantic Search**: Finding similar historical SRs from a 1.18M+ record database
2. **Java Detection**: Using 5-source voting to determine if issues are Java/backend errors
3. **Activity Extraction**: Identifying Java activity names and validating against PostgreSQL
4. **AI Resolution**: Generating comprehensive, grounded workarounds
5. **Intelligent Assignment**: Skill-based team member assignment with load balancing

### Key Metrics

| Metric | Value |
|--------|-------|
| Historical Records | 1,180,000+ |
| LLM Calls per SR | 3-5 (adaptive) |
| Semantic Model | all-MiniLM-L6-v2 |
| Vector Store | ChromaDB |
| Average Processing | ~15 seconds/SR |

---

## âœ¨ Key Features

### ğŸ” Semantic Search
- **ChromaDB Vector Store** with sentence-transformer embeddings
- **Text Preprocessing** to remove noise (customer info, timestamps, IDs)
- **Similarity Threshold** filtering for quality matches

### ğŸ—³ï¸ 5-Source Voting System
Determines if an SR is a Java/backend error by voting from:
1. Resolution Categories (current + similar SRs)
2. Semantic Workaround content
3. AI-generated workarounds from similar SRs
4. User-corrected workarounds from history
5. Current SR description/notes content

### ğŸ”„ Activity Extraction with Retry
- Extracts Java activity names from SR content
- Validates against PostgreSQL database
- Up to 2 retry attempts with alternative suggestions

### ğŸ¤– Anti-Hallucination Prompts
- All file paths must come from provided context
- Class names validated against known activities
- Uncertain items marked as `[NEEDS INVESTIGATION]`

### ğŸ‘¥ Skill-Based Assignment
- Matches SR complexity to team member skill levels
- Considers current workload and availability
- Equal distribution with priority handling

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    SR-ANALYZER ARCHITECTURE                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Excel Uploadâ”‚ â”€â”€â–¶ â”‚ Preprocessor â”‚ â”€â”€â–¶ â”‚ Semantic Search â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                     â”‚           â”‚
â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜           â”‚
â”‚                      â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              5-LLM RAG PIPELINE                          â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â” â”‚   â”‚
â”‚  â”‚  â”‚ LLM 1   â”‚ â”‚ LLM 2   â”‚ â”‚ LLM 3   â”‚ â”‚LLM 4a â”‚ â”‚LLM 5 â”‚ â”‚   â”‚
â”‚  â”‚  â”‚Workaroundâ”‚ â”‚Java Voteâ”‚ â”‚Activity â”‚ â”‚  or   â”‚ â”‚Assignâ”‚ â”‚   â”‚
â”‚  â”‚  â”‚ Finder  â”‚ â”‚ System  â”‚ â”‚Extract  â”‚ â”‚ LLM 4bâ”‚ â”‚ment  â”‚ â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”˜ â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                      â”‚                                          â”‚
â”‚                      â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ChromaDB Mergeâ”‚  â”‚Excel Output  â”‚  â”‚Team Assignment Reportâ”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”— 5-LLM Pipeline

### LLM Call 1: Find Semantic Workaround
**Trigger**: When semantic search similarity < 50%
- Analyzes historical matches to extract best workaround
- Filters garbage workarounds (NA, escalated, closed, etc.)
- Combines multiple workarounds if needed

### LLM Call 2: Java Error Detection
**Always runs** - Uses 5-source voting mechanism:
```
Confidence Levels:
â”œâ”€â”€ HIGH:     â‰¥80% agreement with â‰¥3 meaningful votes
â”œâ”€â”€ MEDIUM:   â‰¥67% agreement with â‰¥3 meaningful votes
â”œâ”€â”€ LOW:      â‰¥60% agreement
â””â”€â”€ VERY_LOW: <60% agreement
```

### LLM Call 3: Extract Activity Names
**Trigger**: Only if Java error detected
- Extracts CamelCase activity names (ValidateAddress, CreateOrder, etc.)
- Validates against PostgreSQL database
- Retry loop with alternative suggestions if not found

### LLM Call 4a: Java Resolution
**Trigger**: If `is_java_error = true`
- Uses validated activities and implementation classes
- References actual Java code from codebase
- Generates 8-12 step workaround with anti-hallucination rules

### LLM Call 4b: General Resolution
**Trigger**: If `is_java_error = false`
- Adapts historical workaround patterns
- Uses SR-specific data (IDs, names from SR)
- Marks missing info as `[NEEDS INVESTIGATION]`

### LLM Call 5: Skill-Based Assignment
**Always runs** - Intelligent team assignment:
- Checks availability (0% = skip)
- Validates workload capacity
- Matches skill level to SR complexity
- Returns single team member name

---

## ğŸš€ Quick Start

### Prerequisites
- Python 3.10, 3.11, or 3.12 (required for numpy/pandas compatibility)
- API tokens in `tokens/Tokens.xlsx`

---

### ğŸ†• First Time Setup

Use the first-time setup script to install all dependencies:

**Windows:**
```cmd
cd semantic-resolution
First_time_MultiModel.bat
```

**Linux/Mac:**
```bash
cd semantic-resolution
chmod +x First_time_MultiModel.sh
./First_time_MultiModel.sh
```

This script will:
1. âœ… Check/verify Python 3.10-3.12
2. âœ… Install all Python dependencies
3. âœ… Verify `tokens/Tokens.xlsx` exists
4. âœ… Check vector stores and databases
5. âœ… Start the Flask application

---

### ğŸ”„ Regular Startup (After First Time)

**Windows:**
```cmd
cd semantic-resolution
START_MULTIMODEL_RAG.bat
```

**Linux/Mac:**
```bash
cd semantic-resolution
./START_MULTIMODEL_RAG.sh
```

---

### ğŸ“ Manual Setup Steps

If you prefer manual setup or the scripts fail:

```bash
# 1. Navigate to project
cd semantic-resolution

# 2. Create virtual environment (optional but recommended)
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/Mac: source venv/bin/activate

# 3. Install dependencies
pip install --upgrade pip setuptools wheel
pip install -r requirements.txt
pip install langchain langchain-core langchain-community chromadb

# 4. Verify tokens file exists
# Create tokens/Tokens.xlsx with columns: Email, Token

# 5. Set PostgreSQL environment variables
# Windows:
set DB_HOST=inoscmm2181
set DB_PORT=30432
set DB_NAME=paasdb
set DB_USER=ossdb01ref
set DB_PASSWORD=ossdb01ref

# Linux/Mac:
export DB_HOST=inoscmm2181
export DB_PORT=30432
export DB_NAME=paasdb
export DB_USER=ossdb01ref
export DB_PASSWORD=ossdb01ref

# 6. Start the application
python app/sr_feedback_app.py
```

---

### ğŸ§ Linux/Mac Compatibility

| Feature | Windows | Linux/Mac |
|---------|---------|-----------|
| Flask Web App | âœ… Works | âœ… Works |
| RAG Pipeline | âœ… Works | âœ… Works |
| ChromaDB | âœ… Works | âœ… Works |
| Semantic Search | âœ… Works | âœ… Works |
| PostgreSQL Activity Lookup | âœ… Works | âœ… Works |
| **Outlook Email Fetcher** | âœ… Works | âŒ Not Supported |
| Team Management | âœ… Works | âœ… Works |

> âš ï¸ **Linux Note**: The Outlook email fetcher (`email_fetcher.py`) uses Windows COM interface (`win32com`) and **only works on Windows**. On Linux/Mac, you must manually upload Excel files through the admin portal instead of automatic email fetching.

---

### ğŸ”— Access Points

After starting the application:

| Portal | URL | Credentials |
|--------|-----|-------------|
| User Portal | http://localhost:5000 | No login required |
| Admin Portal | http://localhost:5000/admin | admin / admin123 |

---

## ğŸ“ Project Structure

```
sr-analyzer/
â””â”€â”€ semantic-resolution/           # Main application directory
    â”œâ”€â”€ admin/                     # Admin portal functionality
    â”‚   â”œâ”€â”€ email/                 # Outlook email integration
    â”‚   â”‚   â”œâ”€â”€ email_fetcher.py          # Fetch daily reports from Outlook
    â”‚   â”‚   â””â”€â”€ email_to_rag_processor.py # Process email attachments
    â”‚   â””â”€â”€ upload/                # File upload processing
    â”‚       â”œâ”€â”€ admin_upload_and_merge_with_rag.py  # Main upload flow
    â”‚       â””â”€â”€ admin_upload_and_merge.py           # Legacy upload
    â”‚
    â”œâ”€â”€ analyzers/                 # SR Analysis Components
    â”‚   â”œâ”€â”€ batch_sr_analyser.py          # AIEnhancedServiceRequestAnalyzer
    â”‚   â”œâ”€â”€ comprehensive_sr_analyzer.py  # Wrapper for legacy compatibility
    â”‚   â””â”€â”€ sr_text_preprocessor.py       # Text cleaning for semantic search
    â”‚
    â”œâ”€â”€ app/                       # Flask Web Application
    â”‚   â”œâ”€â”€ sr_feedback_app.py     # Application entry point
    â”‚   â”œâ”€â”€ routes/                # URL route handlers
    â”‚   â”‚   â”œâ”€â”€ admin.py           # Admin portal routes
    â”‚   â”‚   â”œâ”€â”€ user.py            # User portal routes
    â”‚   â”‚   â”œâ”€â”€ team.py            # Team management routes
    â”‚   â”‚   â”œâ”€â”€ api.py             # REST API endpoints
    â”‚   â”‚   â””â”€â”€ auth.py            # Authentication routes
    â”‚   â””â”€â”€ utils/                 # Helper functions
    â”‚       â”œâ”€â”€ helpers.py         # Utility functions
    â”‚       â”œâ”€â”€ decorators.py      # Route decorators
    â”‚       â””â”€â”€ state.py           # Shared application state
    â”‚
    â”œâ”€â”€ assignment/                # SR Assignment Logic
    â”‚   â”œâ”€â”€ daily_data_manager.py         # Daily upload management
    â”‚   â””â”€â”€ priority_age_calculator.py    # Business day calculations
    â”‚
    â”œâ”€â”€ config/                    # Configuration
    â”‚   â”œâ”€â”€ settings.py            # Application settings
    â”‚   â””â”€â”€ paths.py               # Path constants
    â”‚
    â”œâ”€â”€ data/                      # Data Storage
    â”‚   â”œâ”€â”€ database/              # SQLite databases
    â”‚   â”‚   â”œâ”€â”€ people_skills.db   # Team skills & availability
    â”‚   â”‚   â”œâ”€â”€ sr_tracking.db     # SR tracking data
    â”‚   â”‚   â””â”€â”€ abbreviation.db    # Abbreviation mappings
    â”‚   â””â”€â”€ vectorstore/           # Vector embeddings
    â”‚       â””â”€â”€ chromadb_store/    # ChromaDB collections
    â”‚           â”œâ”€â”€ clean_history_data  # Historical SR embeddings
    â”‚           â”œâ”€â”€ java_mapping        # Java class metadata
    â”‚           â””â”€â”€ comcast_code        # Backend code embeddings
    â”‚
    â”œâ”€â”€ RAG/                       # RAG Pipeline Components
    â”‚   â”œâ”€â”€ rag/                   # Core pipeline
    â”‚   â”‚   â””â”€â”€ multi_model_rag_pipeline_chatgpt.py  # 5-LLM pipeline
    â”‚   â”œâ”€â”€ pipeline/              # Pipeline utilities
    â”‚   â”‚   â””â”€â”€ activity_name_finder.py  # PostgreSQL activity lookup
    â”‚   â”œâ”€â”€ utils/                 # RAG utilities
    â”‚   â”‚   â””â”€â”€ history_db_manager.py    # ChromaDB management
    â”‚   â”œâ”€â”€ creation/              # Vectorstore creation scripts
    â”‚   â”œâ”€â”€ input/                 # Input Excel files
    â”‚   â””â”€â”€ llm output/            # Generated results
    â”‚
    â”œâ”€â”€ team/                      # Team Management
    â”‚   â””â”€â”€ people_skills_database.py    # Skills DB with ML learning
    â”‚
    â”œâ”€â”€ user/                      # User Portal
    â”‚   â””â”€â”€ feedback/              # User feedback collection
    â”‚       â””â”€â”€ user_feedback_manager.py
    â”‚
    â”œâ”€â”€ workaround/                # Workaround Tools
    â”‚   â”œâ”€â”€ resolution_mapping_retriever.py  # Resolution search
    â”‚   â””â”€â”€ extract_workarounds_by_category.py
    â”‚
    â”œâ”€â”€ templates/                 # HTML Templates
    â”œâ”€â”€ tokens/                    # API Token Storage
    â”œâ”€â”€ models/                    # ML Models (sentence-transformers)
    â”œâ”€â”€ input/                     # Input files staging
    â””â”€â”€ output/                    # Output files
```

---

## âš™ï¸ Configuration

### API Tokens (`tokens/Tokens.xlsx`)
```
| Email                  | Token           |
|------------------------|-----------------|
| user1@company.com      | your-api-token1 |
| user2@company.com      | your-api-token2 |
```

### Team Configuration (`People.xlsx`)
```
| Team Member    | App     | Skill Level | Max Load | Specialization      |
|----------------|---------|-------------|----------|---------------------|
| John Smith     | SOM_MM  | 4.5/5       | 12       | Java/Provisioning   |
| Jane Doe       | SQO_MM  | 3.5/5       | 10       | Orders/Billing      |
```

### Environment Variables
```bash
# Optional: Override default paths
export SR_DATA_DIR=/path/to/data
export SR_TOKENS_FILE=/path/to/Tokens.xlsx
```

---

## ğŸ“– Usage

### 1. Admin: Upload Daily SR Report
1. Navigate to `http://localhost:5000/admin`
2. Click "Upload Excel" and select your SR report
3. System automatically:
   - Runs semantic search
   - Executes 5-LLM pipeline
   - Merges to ChromaDB
   - Assigns team members
4. Download results from "Reports" section

### 2. User: Provide Feedback
1. Navigate to `http://localhost:5000`
2. Search for an SR by ID
3. View AI-generated workaround
4. Submit corrections if needed
5. Feedback is stored for ML improvement

### 3. Programmatic Usage
```python
from RAG.rag.multi_model_rag_pipeline_chatgpt import MultiModelSRPipeline

# Initialize pipeline
pipeline = MultiModelSRPipeline(
    tokens_file="tokens/Tokens.xlsx",
    model_name="gpt-4.1"
)

# Analyze single SR
sr_data = {
    'SR ID': 'CAS123456',
    'Description': 'Network connectivity issue...',
    'Notes': 'Customer reports intermittent...',
    'Priority': 'P2'
}
result = pipeline.analyze_single_sr(sr_data)

# Access results
print(f"Is Java Error: {result['Is Java Error']}")
print(f"AI Workaround: {result['AI Workaround']}")
print(f"Assigned To: {result['Assigned To']}")
```

---

## ğŸ”Œ API Reference

### REST Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/api/analyze` | POST | Analyze single SR |
| `/api/search` | GET | Search historical SRs |
| `/api/feedback` | POST | Submit workaround feedback |
| `/api/team/status` | GET | Get team availability |
| `/admin/upload` | POST | Upload Excel file |

### Python API

```python
# Semantic Search
from RAG.utils.history_db_manager import HistoryDatabaseManager
manager = HistoryDatabaseManager()
results = manager.search_semantic("connectivity issue", top_k=5)

# Team Skills
from team.people_skills_database import PeopleSkillsDatabase
db = PeopleSkillsDatabase()
experts = db.get_top_experts("SOM_MM", top_n=3)

# Activity Lookup
from RAG.pipeline.activity_name_finder import ActivityFinder
finder = ActivityFinder()
result = finder.find_activity_implementation("ValidateAddress")
```

---

## ğŸ“Š Data Flow

```
1. INPUT: Excel Upload (SR Report)
        â†“
2. PREPROCESSING: Clean text, standardize columns
        â†“
3. SEMANTIC SEARCH: Query ChromaDB for similar SRs
        â†“
4. LLM PIPELINE: 5 specialized LLM calls
        â†“
5. VALIDATION: Activity names validated against PostgreSQL
        â†“
6. ASSIGNMENT: Skill-based team member selection
        â†“
7. OUTPUT: Excel with AI Workarounds + Assignments
        â†“
8. MERGE: Update ChromaDB with new SRs
```

---

## ğŸ› ï¸ Development

### Adding New Team Members
1. Edit `People.xlsx` with new member details
2. Run: `python -c "from team.people_skills_database import PeopleSkillsDatabase; PeopleSkillsDatabase().load_people_from_excel()"`

### Creating New Vectorstore
```bash
cd semantic-resolution/RAG/creation
python create_history_vectorstore.py
```

### Running Tests
```bash
cd semantic-resolution
python -m pytest tests/
```

---

## ğŸ“ License

Internal Use Only - Amdocs/Comcast Project

---

## ğŸ‘¥ Contributors

- **Praveer Dubey** - Lead Developer
- **Team** - SR Analysis & Support

---

*Last Updated: January 2026*
